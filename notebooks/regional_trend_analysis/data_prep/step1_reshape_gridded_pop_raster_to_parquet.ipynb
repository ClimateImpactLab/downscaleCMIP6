{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c4726e0-8890-4817-8e77-b1fc6d5035c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/dask_gateway/client.py:21: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import LoopRunner, format_bytes\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import fsspec\n",
    "import dask.dataframe as ddf\n",
    "from zarr.errors import GroupNotFoundError\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "import rhg_compute_tools.kubernetes as rhgk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab2d7cb2-8c42-40f0-9c30-2c5b8ef8b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem('gs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c69d241c-7a27-4694-9ea6-3874cc312af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRS_SUPPORT_BUCKET = os.environ['CRS_SUPPORT_BUCKET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662a4705-97ee-4081-8aad-57225db2937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_fp = (\n",
    "    f'gs://{CRS_SUPPORT_BUCKET}/public_datasets/spatial/exposure/GLOBAL/population/'\n",
    "    'gpw-v4-population-count-adjusted-to-2015-unwpp-country-totals-rev11_2020_30_sec_tif/'\n",
    "    'gpw_v4_population_count_adjusted_to_2015_unwpp_country_totals_rev11_2020_30_sec_tif_readme.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ed8f15-1563-48f4-83df-d92fac3376cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_patt = (\n",
    "    'gs://{CRS_SUPPORT_BUCKET}/public_datasets/spatial/exposure/GLOBAL/{category}/'\n",
    "    '{dataset}_{native_res}_tif/'\n",
    "    '{dataset_underscore}_{native_res}.tif'\n",
    ")\n",
    "\n",
    "output_data = (\n",
    "    'gs://{CRS_SUPPORT_BUCKET}/public_datasets/spatial/exposure/GLOBAL/'\n",
    "    '{category}/{dataset}_{native_res}_tif/derived_datasets/{kind}/{name}.{ext}'\n",
    ")\n",
    "\n",
    "NATIVE_RES = '30_sec'\n",
    "\n",
    "POPULATION_CITATION = (\n",
    "    'Center for International Earth Science Information Network - CIESIN - '\n",
    "    'Columbia University. 2018. Gridded Population of the World, Version 4 '\n",
    "    '(GPWv4): Population Count Adjusted to Match 2015 Revision of UN WPP '\n",
    "    'Country Totals, Revision 11. Palisades, NY: NASA Socioeconomic Data and '\n",
    "    'Applications Center (SEDAC). https://doi.org/10.7927/H4PN93PB. '\n",
    "    'Accessed 18 Feb 2022.'\n",
    ")\n",
    "\n",
    "LANDWATER_CITATION = (\n",
    "    'Center for International Earth Science Information Network - CIESIN - '\n",
    "    'Columbia University. 2018. Gridded Population of the World, Version 4 '\n",
    "    '(GPWv4): Land and Water Area, Revision 11. Palisades, NY: NASA '\n",
    "    'Socioeconomic Data and Applications Center (SEDAC). '\n",
    "    'https://doi.org/10.7927/H4Z60M4Z. Accessed 24 Feb 2022.'\n",
    ")\n",
    "\n",
    "POP_CAT = 'population'\n",
    "POP_VAR_NAME = 'population'\n",
    "POP_UNIT = 'count'\n",
    "POP_DATASET = 'gpw-v4-population-count-adjusted-to-2015-unwpp-country-totals-rev11_2020'\n",
    "POP_URL = 'https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-count-adjusted-to-2015-unwpp-country-totals-rev11'\n",
    "POP_CITATION = POPULATION_CITATION\n",
    "\n",
    "LAND_CAT = 'land_water_area'\n",
    "LAND_VAR_NAME = 'land_area'\n",
    "LAND_UNIT = 'km^2'\n",
    "LAND_DATASET = 'gpw-v4-land-water-area-rev11_landareakm'\n",
    "LAND_URL = 'https://sedac.ciesin.columbia.edu/data/set/gpw-v4-land-water-area-rev11'\n",
    "LAND_CITATION = LANDWATER_CITATION\n",
    "\n",
    "WATER_CAT = 'land_water_area'\n",
    "WATER_VAR_NAME = 'water_area'\n",
    "WATER_UNIT = 'km^2'\n",
    "WATER_DATASET = 'gpw-v4-land-water-area-rev11_waterareakm'\n",
    "WATER_URL = 'https://sedac.ciesin.columbia.edu/data/set/gpw-v4-land-water-area-rev11'\n",
    "WATER_CITATION = LANDWATER_CITATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e809fd3e-55bd-4fe2-b138-4b91738a4938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd082878a1b64947a09f6051858edaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client, cluster = rhgk.get_giant_cluster()\n",
    "cluster.scale(30)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae23ca2-d183-419b-8fcf-bdd77bcfd0c0",
   "metadata": {},
   "source": [
    "# Convert to different formats\n",
    "\n",
    "* The zarr version is an exact replica of the GeoTiff, just chunked & in a cloud-optimized format\n",
    "* The parquet file is converted to a columnar format, and all zero values are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1edd5943-557b-4a5f-993b-ee21631b4f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40c724bc07f436683acd20c53540e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "coarsen:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6300/204391691.py:96: RuntimeWarning: Failed to open Zarr store with consolidated metadata, falling back to try reading non-consolidated metadata. This is typically much slower for opening a dataset. To silence this warning, consider:\n",
      "1. Consolidating metadata in this existing store with zarr.consolidate_metadata().\n",
      "2. Explicitly setting consolidated=False, to avoid trying to read consolidate metadata, or\n",
      "3. Explicitly setting consolidated=True, to raise an error in this case instead of falling back to try reading non-consolidated metadata.\n",
      "  xr.open_zarr(fmt_coarsened_zarr)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "coarsen:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "coarsen:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for category, dataset, url, citation, varname, unit in tqdm([\n",
    "    (POP_CAT, POP_DATASET, POP_URL, POP_CITATION, POP_VAR_NAME, POP_UNIT),\n",
    "    (LAND_CAT, LAND_DATASET, LAND_URL, LAND_CITATION, LAND_VAR_NAME, LAND_UNIT),\n",
    "    (WATER_CAT, WATER_DATASET, WATER_URL, WATER_CITATION, WATER_VAR_NAME, WATER_UNIT),\n",
    "], desc='dataset'):\n",
    "\n",
    "    fmt_zarr = output_data.format(\n",
    "        CRS_SUPPORT_BUCKET=CRS_SUPPORT_BUCKET,\n",
    "        kind='reformatted',\n",
    "        category=category,\n",
    "        dataset=dataset,\n",
    "        native_res=NATIVE_RES,\n",
    "        name=f'{dataset}_{NATIVE_RES}',\n",
    "        ext='zarr',\n",
    "    )\n",
    "\n",
    "    fmt_parquet = output_data.format(\n",
    "        CRS_SUPPORT_BUCKET=CRS_SUPPORT_BUCKET,\n",
    "        kind='reformatted',\n",
    "        category=category,\n",
    "        dataset=dataset,\n",
    "        native_res=NATIVE_RES,\n",
    "        name=f'{dataset}_{NATIVE_RES}',\n",
    "        ext='parquet',\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        mapper = fs.get_mapper(fmt_zarr)\n",
    "        ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    except (FileNotFoundError, GroupNotFoundError, IOError, KeyError):\n",
    "        if fs.isdir(fmt_zarr):\n",
    "            raise IOError(f'Error reading {fmt_zarr}')\n",
    "\n",
    "        source_fp = source_patt.format(\n",
    "            CRS_SUPPORT_BUCKET=CRS_SUPPORT_BUCKET,\n",
    "            category=category,\n",
    "            dataset=dataset,\n",
    "            dataset_underscore=dataset.replace('-', '_'),\n",
    "            native_res=NATIVE_RES,\n",
    "        )\n",
    "\n",
    "        with xr.open_rasterio(source_fp, chunks={'x':  2160, 'y': 2160}) as da:\n",
    "            ds = da.to_dataset(name=varname)\n",
    "            ds.attrs.update({\n",
    "                'method': 'Converted to zarr array from original GeoTiff for ease of access. No other modifications made.',\n",
    "                'updated': pd.Timestamp.now(tz='US/Pacific').strftime('%c (%Z)'),\n",
    "                'version': 'v4r11',\n",
    "                'url': url,\n",
    "                'citation': citation,\n",
    "            })\n",
    "\n",
    "            ds.to_zarr(fmt_zarr, consolidated=True)\n",
    "\n",
    "        mapper = fs.get_mapper(fmt_zarr)\n",
    "        ds = xr.open_zarr(mapper, consolidated=True)\n",
    "\n",
    "    try:\n",
    "        df = ddf.read_parquet(fmt_parquet)\n",
    "    except (FileNotFoundError, IOError):\n",
    "        df = ds.to_dask_dataframe()\n",
    "        df = df[df[varname] > 0]\n",
    "        df.repartition(partition_size='200MB')\n",
    "        df.to_parquet(fmt_parquet)\n",
    "\n",
    "        df = ddf.read_parquet(fmt_parquet)\n",
    "        \n",
    "    for RES, RES_NAME in tqdm([\n",
    "        (0.1, '0.1degree'),\n",
    "        (0.125, '0.125degree'),\n",
    "        (0.25, '0.25degree'),\n",
    "        (0.5, '0.5degree'),\n",
    "        (1, '1degree'),\n",
    "    ], desc='coarsen', leave=False):\n",
    "\n",
    "        fmt_coarsened_parquet = output_data.format(\n",
    "            CRS_SUPPORT_BUCKET=CRS_SUPPORT_BUCKET,\n",
    "            kind='coarsened',\n",
    "            category=category,\n",
    "            dataset=dataset,\n",
    "            native_res=NATIVE_RES,\n",
    "            name=f'{dataset}_{RES_NAME}',\n",
    "            ext='parquet',\n",
    "        )\n",
    "\n",
    "        fmt_coarsened_zarr = output_data.format(\n",
    "            CRS_SUPPORT_BUCKET=CRS_SUPPORT_BUCKET,\n",
    "            kind='coarsened',\n",
    "            category=category,\n",
    "            dataset=dataset,\n",
    "            native_res=NATIVE_RES,\n",
    "            name=f'{dataset}_{RES_NAME}',\n",
    "            ext='zarr',\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            xr.open_zarr(fmt_coarsened_zarr, consolidated=True)\n",
    "            continue\n",
    "        except (FileNotFoundError, GroupNotFoundError):\n",
    "            pass\n",
    "\n",
    "        grouped = df[[varname]].assign(lat=(((df.y // RES) + 0.5) * RES), lon=(((df.x // RES) + 0.5) * RES)).groupby(['lat', 'lon']).sum()\n",
    "        grouped.reset_index(drop=False).repartition(partition_size='200MB').to_parquet(fmt_coarsened_parquet)\n",
    "\n",
    "        coarsened = grouped.compute().to_xarray().fillna(0)\n",
    "        coarsened[varname].attrs.update({\n",
    "            'long_name': varname,\n",
    "            'units': unit,\n",
    "            'crs': ds[varname].attrs['crs'],\n",
    "        })\n",
    "\n",
    "        coarsened.attrs.update(ds.attrs)\n",
    "        coarsened.attrs.update({\n",
    "            'method': f'{varname} summed from 30-as source data',\n",
    "            'resolution_degrees': RES,\n",
    "            'resolution_description': RES_NAME,\n",
    "        })\n",
    "\n",
    "        coarsened.to_zarr(fmt_coarsened_zarr, consolidated=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58ec3c2-5a8e-4f9b-b100-bcfbc85ad20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()\n",
    "cluster.scale(0)\n",
    "client.close()\n",
    "cluster.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1def5f9e-8570-4375-9d99-467e3b5dc2db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
