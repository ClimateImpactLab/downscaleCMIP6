{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739d29da-eb1b-4f4a-993f-692bd40df7ee",
   "metadata": {},
   "source": [
    "## Notebook for tasmax's northern hemisphere summer 95th percentile maps in GDPCIR paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b7eda1-b61a-4327-9c93-6d27a8913e94",
   "metadata": {},
   "source": [
    "#### last updated : 2022/11/15, by Emile Tenezakis (e.tenezakis@gmail.com). \n",
    "#### scaling : with a remote dask cluster as a backend to the xarray datasets. With the cluster scaling parameters as is, notebook should take around 10 minutes, including normal cluster spin up time. \n",
    "#### output : notebook saves the figure to user specific `figure_3_output_file_path` defined below.\n",
    "#### library dependencies : This ran on rhodium's onyx environment, with the open source rhodium `rhg_compute_tools` and open source `dodola` packages pip-installed in editable mode (if using onyx, install both without their dependencies with the `--no-deps` flag).  \n",
    "#### data dependencies : publicly available GDPCIR datasets stored on google cloud, and a yaml file containing the URLs to these datasets. This yaml file is available in the GDPCIR github repository, specify your local path to it below with `fps_yaml_path`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bff41c-88a2-4d17-9edb-22dbae75eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_3_output_file_path = '/home/jovyan/tests/fig3_v0.png' # put that wherever you want\n",
    "fps_yaml_path = '/home/jovyan/repositories/downscaleCMIP6/notebooks/downscaling_pipeline/post_processing_and_delivery/data_paths.yaml'\n",
    "model = 'NorESM2-LM'\n",
    "fut_scenario = 'ssp370'\n",
    "var = 'tasmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24229d-19ff-4b2f-8d45-08629c01dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from rhg_compute_tools import kubernetes as rhgk\n",
    "from dodola.services import xesmf_regrid\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a7d2ba-8ce2-48cd-821d-74d693bd8d35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# each 50 workers get 1/2 a 48GiB Node. \n",
    "# necessary to use half a node b/c of reanalysis. \n",
    "client, cluster = rhgk.get_big_cluster()\n",
    "cluster.scale(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6b415c-ad46-4227-9f27-ec1ab109adb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128dee43-3018-4e7c-a553-d92b129ebd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcm_q_trend(model, fut_scenario, var, step_label, fut_period=range(2080, 2100+1), hist_period=range(1995, 2014+1), months=[6,7,8], quantile=0.95, pix=None) -> xr.DataArray():\n",
    "    \n",
    "    \"\"\"\n",
    "    function that loads GCM data at the step `step_label` (raw, bias corrected, downscaled etc) from the URLs yaml file and computes the trend in a particular seasonal quantile of tasmax for `model`, scenario `fut_scenario`, variable `var. Trend is computed between `fut_period` and `hist_period`. Season is defined with `months`. Quantile is defined with `quantile`. \n",
    "    \n",
    "    You can locally, without the dask cluster, test the function with `pix`.\n",
    "    \"\"\"\n",
    "    with open(fps_yaml_path, 'r') as f:\n",
    "        fps = yaml.load(f, yaml.Loader)\n",
    "    hist_scenario_label = 'historical'\n",
    "    fut = xr.open_zarr(fps[f'{model}-{var}'][fut_scenario][step_label])[var]\n",
    "    if pix is not None:\n",
    "        fut = fut.isel(lat=pix['lat'], lon=pix['lon'], drop=True)\n",
    "    fut = fut.where(fut.time.dt.year.isin(fut_period), drop=True)\n",
    "    hist = xr.open_zarr(fps[f'{model}-{var}'][hist_scenario_label][step_label])[var]\n",
    "    if pix is not None:\n",
    "        hist = hist.isel(lat=pix['lat'], lon=pix['lon'], drop=True)\n",
    "    hist = hist.where(hist.time.dt.year.isin(hist_period), drop=True)\n",
    "    \n",
    "    fut = fut.where(fut.time.dt.month.isin(months), drop=True)\n",
    "    hist = hist.where(hist.time.dt.month.isin(months), drop=True)\n",
    "    \n",
    "    if pix is not None:\n",
    "        fut = fut.load()\n",
    "        hist = hist.load()\n",
    "    else:\n",
    "        # move chunks to space to take temporal quantile\n",
    "        fut = fut.chunk({'time': -1, 'lat': 360, 'lon': 360})\n",
    "        hist = hist.chunk({'time': -1, 'lat': 360, 'lon': 360})\n",
    "\n",
    "    fut_q = fut.quantile(q=quantile, dim='time')\n",
    "    hist_q = hist.quantile(q=quantile, dim='time')\n",
    "    trend = fut_q - hist_q\n",
    "    \n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dada08cd-a394-4e98-a25c-a1c45d167dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_q(period=range(1995, 2014+1),months=[6,7,8],quantile=0.95, pix=None) -> xr.DataArray():\n",
    "\n",
    "    \"\"\"\n",
    "    function that loads tasmax reanalysis data and computes the `quantile` of the time series subset defined by `period` (years) and `months` (seasonality). \n",
    "    \n",
    "    You can locally, without the dask cluster, test the function with `pix`.\n",
    "    \"\"\"\n",
    "    \n",
    "    ref_da = xr.open_zarr('gs://clean-b1dbca25/reanalysis/ERA-5/F320/tasmax.1995-2015.F320.zarr')['tasmax']\n",
    "    if pix is not None:\n",
    "        ref_da = ref_da.isel(lat=pix['lat'], lon=pix['lon'], drop=True)\n",
    "    ref_da = ref_da.where(ref_da.time.dt.year.isin(period), drop=True)\n",
    "    ref_da = ref_da.where(ref_da.time.dt.month.isin(months), drop=True)\n",
    "    if pix is not None:\n",
    "        ref_da = ref_da.load()\n",
    "    else:\n",
    "        # move chunks to space to take temporal quantile\n",
    "        ref_da = ref_da.chunk({'time':-1, 'lat':360, 'lon':360})\n",
    "    ref_q = ref_da.quantile(q=quantile, dim='time')\n",
    "    return ref_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473c4b8-0cd2-42d7-9d14-711a5cb24b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_to_downscaled_resolution(da):\n",
    "    \"\"\"\n",
    "    regrid a lat/lon dataarray to the downscaling resolution using dodola's `xesmf_regrid`. \n",
    "    \"\"\"\n",
    "    domain_ds = xr.open_zarr('gs://support-c23ff1a3/domain.0p25x0p25.zarr', chunks=None)\n",
    "    da = xesmf_regrid(x=xr.Dataset({'da':da}), domain=domain_ds, method='nearest_s2d', astype=np.float32, add_cyclic=None, keep_attrs=True)['da']\n",
    "    return da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113436b-9282-40f7-9686-3b7c5c7bed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_lon(da):\n",
    "    \"\"\"\n",
    "    [0, 360] - > [-180, 180]\n",
    "    \"\"\"\n",
    "    return da.assign_coords({'lon':xr.where(da.lon>180, da.lon-360, da.lon)}).sortby('lon')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba0c365-6c0f-4666-abd2-6059660e93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with one pixel\n",
    "# test_trend = trend(model=model, fut_scenario=fut_scenario, var=var, step_label='downscaled_delivered', pix={'lat':300, 'lon':300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a765d97-8603-4f76-8c27-fdf148f0e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    downscaled_trend = gcm_q_trend(model=model, fut_scenario=fut_scenario, var=var, step_label='downscaled_delivered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee69be-b13e-450d-aec2-76e12bf3a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "downscaled_trend = downscaled_trend.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ecd1da-d756-4f04-bfd1-04942e468df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cleaned_trend = gcm_q_trend(model=model, fut_scenario=fut_scenario, var=var, step_label='clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0cd57c-72ed-4996-868f-e5ba6bbfe996",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cleaned_trend = raw_cleaned_trend.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4adb4-c0e4-4576-8bf3-19fee3b0bf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cleaned_trend = cyclic_lon(raw_cleaned_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf4b7f-ca28-4756-b354-cc9d5a92556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cleaned_trend_regridded = regrid_to_downscaled_resolution(raw_cleaned_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0a3cb1-c29b-46a2-ac1d-4024017f4c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_downscaled_regriddedraw = (downscaled_trend - raw_cleaned_trend_regridded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7039e250-a464-4d5f-b949-ade8a9f0a6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on one pixel\n",
    "# test_ref_q = ref_q(pix={'lat':300, 'lon':300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92e21f-c711-4bbb-9f18-ab733ca43005",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
    "    reference_quantile = ref_q()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa9e03-f819-46a6-887c-46bc0c414072",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_quantile = reference_quantile.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8176f4cc-2fc9-48f1-8b10-6f8c6e6a571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_quantile = cyclic_lon(reference_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694e6fe-39e1-4bb4-a124-f45a4c097b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kwargs = dict(cmap='viridis', vmin=0, vmax=10)\n",
    "diff_plot_kwargs = dict(cmap='viridis', vmin=-1, vmax=1)\n",
    "abs_plot_kwargs = dict(cmap='viridis', vmin=230, vmax=315)\n",
    "all_pieces = [raw_cleaned_trend, downscaled_trend, diff_downscaled_regriddedraw]\n",
    "titles = ['(A) change in model', '(B) change in downscaled', '(C) difference in change (downscaled - model)']\n",
    "kwargs_list = [plot_kwargs, plot_kwargs, diff_plot_kwargs]\n",
    "from copy import copy\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "all_pieces_copy = copy(all_pieces)\n",
    "fig, axes = plt.subplots(ncols=len(all_pieces_copy), nrows=1, figsize=(8*len(all_pieces_copy), 6))\n",
    "for i,_ in enumerate(all_pieces_copy):\n",
    "    v, k, kw, ax = all_pieces_copy[i], titles[i], kwargs_list[i], axes[i]\n",
    "    v['lat'].attrs = dict()\n",
    "    v['lon'].attrs = dict()\n",
    "    im = all_pieces[i].plot(add_colorbar=False, ax=ax, **kwargs_list[i])\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size='3%', pad=0.15)\n",
    "    fig.colorbar(im, cax=cax, orientation='vertical', extend='both', label='temperature (K)')\n",
    "    ax.set_title(titles[i])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "fig.suptitle('95th Percentile JJA Maximum Temperature. SSP3-7.0. NorESM2-LM')\n",
    "plt.savefig(figure_3_output_file_path, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4bce4-82df-46ea-a8a3-a6b88c57079f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
